{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5490a1f2-d580-4d21-95f4-c98df5448237",
   "metadata": {},
   "source": [
    "This notebook reads from a csv, putting the data in a dask dataframe. The data consists of registration data: an accountid and corresponding email address, the user_type (subscriber or registered), the timestamp of the registration, the brand for which they registered and a free text field for a sentence. For both Belgium and Ireland, the notebooks checks every row for a subscription for the corresponding brand which started today, i.e. 'user_type' == \"subscriber\" and 'timestamp' = today. For these cases, a sentence gets translated in the corresponding language and added to the 'sentence' field. When this is done, the dataframe gets written to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e651da6-9b2e-4a39-b97c-2b18e55ba025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some dask workers, because it is a lot of data.\n",
    "dask_client = ut.setup_worker_dask()\n",
    "dask_client.cluster.scale(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197455c4-9abe-4784-8905-ba9cd0602e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from google.cloud import translate_v2 as translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beede73-b5bd-4ccd-a83a-30f0ed6036c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the translater\n",
    "credentials = {\"ID\": \"YLufGTO14mWvJmWZ3roQY4hKm9A12s53BoNBHIyN\", \"SECRET\": \"5A0e7Sr0rIy6zYWQYT6AFuvb3vF6V8WzY9Uxj0MX\"}\n",
    "translate_client = translate.Client(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db498b-2546-493f-b883-adeae53bbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns I want to read.\n",
    "columns_to_read = ['accountid', 'email', 'user_type', 'timestamp', 'brand', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f573530-35ee-465a-8ab9-6d4db72ec0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {\n",
    "    \"be\": {\"language\": \"nl\", \"brand\": \"niewsblad.be\"},\n",
    "    \"ie\": {\"language\": \"en\", \"brand\": \"independent.ie\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c5b6d-b9b4-428a-909b-e05a2811a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the entities\n",
    "for entity in entities:\n",
    "    \n",
    "    # read the csv\n",
    "    df = dd.read_csv('myfiles/file.csv', usecols=columns_to_read)\n",
    "\n",
    "    # and check every row\n",
    "    for row_index in range(len(df)):\n",
    "        \n",
    "        row = df.loc[row_index].compute()\n",
    "        brand = row.brand[row_index]\n",
    "        timestamp = row.timestamp[row_index]\n",
    "        user_type = row.user_type[row_index]\n",
    "        \n",
    "        today = date.today()\n",
    "        \n",
    "        try:\n",
    "            # if the brand is correct, the timestamp is today and the user_type is a subscriber\n",
    "            if brand == entities[entity][\"brand\"]:\n",
    "                if (datetime.fromtimestamp(int(timestamp)).date() == today) & (user_type == \"subscriber\"):\n",
    "\n",
    "                    # then translate the sentence\n",
    "                    sentence = translate_client.translate('Une phrase, que je veux vraiment ajouter au CSV', target_language=entities[entity][\"language\"])\n",
    "\n",
    "                    # add the sentence to the row\n",
    "                    def update_sentence(df, row_index, new_sentence):\n",
    "                        df.loc[df.index == row_index, 'sentence'] = new_sentence\n",
    "                        return df\n",
    "                    meta = df.head(0)\n",
    "                    df = df.map_partitions(update_sentence, row_index, sentence, meta=meta)\n",
    "\n",
    "            # write to csv\n",
    "            df.to_csv(\"myfiles/file.csv\", single_file=True)\n",
    "            \n",
    "        except Exception as error: \n",
    "            print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
